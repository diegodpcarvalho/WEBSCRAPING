# üï∏Ô∏è Web Scraping - Download e Compacta√ß√£o de PDFs üóÇÔ∏è

Este projeto foi desenvolvido como parte de um teste t√©cnico para uma vaga de emprego. Ele demonstra o uso de **Web Scraping** com Python para acessar um site, localizar links de arquivos PDF espec√≠ficos, baix√°-los, e compact√°-los em um √∫nico arquivo ZIP.

---

## üìã Funcionalidades

1. **Acesso autom√°tico ao site da ANS**:
   - O script acessa a p√°gina: [Atualiza√ß√£o do Rol de Procedimentos](https://www.gov.br/ans/pt-br/acesso-a-informacao/participacao-da-sociedade/atualizacao-do-rol-de-procedimentos).

2. **Identifica√ß√£o e download de PDFs espec√≠ficos**:
   - Apenas os anexos **"Anexo I"** e **"Anexo II"** s√£o baixados, ignorando os demais arquivos presentes na p√°gina.

3. **Compacta√ß√£o dos arquivos**:
   - Ap√≥s o download, todos os PDFs s√£o compactados em um √∫nico arquivo ZIP.

4. **Controle de arquivos baixados**:
   - O script mant√©m um controle eficiente para evitar duplicatas e gerenciar os arquivos baixados.

---

## üíª Tecnologias Utilizadas

- **Python 3.10**: Linguagem de programa√ß√£o utilizada no projeto.
- **Bibliotecas**:
  - `requests`: Para realizar requisi√ß√µes HTTP.
  - `BeautifulSoup (bs4)`: Para fazer o parsing do HTML e localizar os links dos PDFs.
  - `zipfile`: Para compactar os arquivos em um arquivo ZIP.
  - `os`: Para gerenciar arquivos no sistema operacional.

---

## üöÄ Como Executar o Projeto

1. **Clonar este reposit√≥rio**:
   ```bash
   git clone https://github.com/diegodpcarvalho/WEBSCRAPING
   cd WEBSCRAPING

## Resultados:

Os arquivos "Anexo I" e "Anexo II" ser√£o baixados e salvos no diret√≥rio do script.

Um arquivo chamado anexos.zip ser√° gerado contendo os PDFs compactados.

## üìÇ Estrutura do C√≥digo
main.py: O script principal que realiza todo o processo de scraping, download e compacta√ß√£o.

Depend√™ncias: Todas as bibliotecas necess√°rias est√£o listadas no arquivo requirements.txt.

## üìù Explica√ß√£o T√©cnica
1Ô∏è‚É£ Web Scraping com BeautifulSoup
O HTML da p√°gina √© carregado e analisado para encontrar os links dos PDFs.

Foi utilizada a fun√ß√£o soup.find_all para localizar <a> tags com os nomes exatos dos arquivos desejados ("Anexo I" e "Anexo II").

2Ô∏è‚É£ Download de PDFs
A biblioteca requests foi usada para fazer o download dos arquivos PDF.

Cada PDF foi salvo localmente com o nome original extra√≠do do link.

3Ô∏è‚É£ Compacta√ß√£o dos Arquivos
Todos os PDFs baixados foram compactados em um √∫nico arquivo ZIP com a biblioteca zipfile.

4Ô∏è‚É£ Boas Pr√°ticas
O script foi projetado para ser robusto, verificando duplicatas e mantendo um controle eficiente dos arquivos baixados.

Links completos e relativos foram tratados de forma gen√©rica, garantindo maior adaptabilidade do c√≥digo.

## üåü Diferenciais
Filtro Inteligente:

Apenas os arquivos relevantes (Anexo I e Anexo II) s√£o processados, economizando tempo e recursos.

C√≥digo Limpo e Bem Documentado:

O script foi escrito com clareza e inclui coment√°rios explicativos para cada etapa.

Adaptabilidade:

O c√≥digo √© gen√©rico o suficiente para ser adaptado a outras p√°ginas que contenham arquivos semelhantes.

Controle de Erros:

Verifica√ß√µes foram adicionadas para lidar com links quebrados ou arquivos n√£o encontrados.

üë®‚Äçüíª Autor
Desenvolvido por Diego de Paula Carvalho.

üìß diegodpcarvalho@gmail.com

üñ•Ô∏è GitHub

